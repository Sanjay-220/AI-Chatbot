{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63564c45-89bb-44fb-b138-d7119bc36626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aeda25e63ebd: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 3.3 GB                         \u001b[K\n",
      "pulling e0a42594d802: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  358 B                         \u001b[K\n",
      "pulling dd084c7d92a3: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 8.4 KB                         \u001b[K\n",
      "pulling 3116c5225075: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   77 B                         \u001b[K\n",
      "pulling b6ae5839783f: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  489 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "! ollama pull gemma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92095f07-62ba-47da-850b-651e7c202a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from langchain.schema import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28211c0-07fd-464b-ab73-a2f325058a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
    "import openpyxl\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e876fac2-0cb3-4f3e-9130-7d24a209105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/2kj6d1ld1w5f46gd1x6cqh2m0000gn/T/ipykernel_2206/1999449518.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma3\", base_url=\"http://127.0.0.1:11434\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"gemma3\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775c2a6b-03f1-4a61-b5ce-bf3a08d060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant named Chitti that provides concise and accurate responses based on the provided dataframe.\n",
    "If the customer greets with Hi or Hello, greet them and introduce yourself.\n",
    "If the customer talks about anything general, respond based on their message.\n",
    "Always be helpful and answer questions about the data in a clear manner.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b357f7-c655-4a22-9cc9-3bedfc016573",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f418c1-8804-4104-99a4-bd07bac8361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    \"\"\"Process the uploaded Excel file and return a message.\"\"\"\n",
    "    global current_agent\n",
    "    \n",
    "    if file is None:\n",
    "        return \"Please upload an Excel file to begin.\"\n",
    "    \n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file.name)\n",
    "        \n",
    "        # Create the agent with only supported parameters\n",
    "        current_agent = create_pandas_dataframe_agent(\n",
    "            llm=llm,\n",
    "            df=df,\n",
    "            verbose=False,\n",
    "            handle_parsing_errors=True,\n",
    "            prefix=system_prompt,allow_dangerous_code= True\n",
    "        )\n",
    "        \n",
    "        # Return the dataframe information\n",
    "        return f\"‚úÖ File loaded successfully!\"\n",
    "    except Exception as e:\n",
    "        current_agent = None\n",
    "        return f\"Error processing file: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1124ba-a068-432a-87fc-ede1268128d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(message, history):\n",
    "    \"\"\"Handle chat interactions with the agent.\"\"\"\n",
    "    global current_agent\n",
    "    \n",
    "    if current_agent is None:\n",
    "        return \"Please upload an Excel file first before asking questions.\"\n",
    "    \n",
    "    try:\n",
    "        messages = history + [{\"role\":\"user\", \"content\":message}]\n",
    "        result = current_agent.invoke({\"input\": messages})\n",
    "        return result['output']\n",
    "    except Exception as e:\n",
    "        x = f\"Error processing your request: {str(e)}\"\n",
    "        y = x.split('Could not parse LLM output: ')[1]\n",
    "        z = y.split('For troubleshooting, visit:')[0]\n",
    "        message = message+z\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f214fc-a4c5-45df-be0d-6a551dae8ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://bfb8a3d78ddf5283df.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bfb8a3d78ddf5283df.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:283: UserWarning: Received additional kwargs {'handle_parsing_errors': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(css=\"\"\"\n",
    "    .gradio-container, .gradio-container > div {\n",
    "        height: 100vh !important;\n",
    "    }\n",
    "    .chat-column {\n",
    "        height: calc(100vh - 140px);\n",
    "    }\n",
    "    .file-column {\n",
    "        height: 50%;\n",
    "    }\n",
    "\"\"\") as demo:\n",
    "    gr.Markdown(\"# üìä Chat with Your Excel Data\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, elem_classes=\"file-column\"):\n",
    "            file_input = gr.File(\n",
    "                label=\"Upload Excel File\",\n",
    "                file_types=[\".xlsx\", \".xls\"],\n",
    "                type=\"filepath\",\n",
    "                scale=1,\n",
    "                min_width=20\n",
    "            )\n",
    "            status_output = gr.Markdown(\"Please upload an Excel file to begin.\")\n",
    "        \n",
    "        with gr.Column(scale=2, elem_classes=\"chat-column\", show_progress = True):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=chat,\n",
    "                fill_height=True, \n",
    "                fill_width=True,\n",
    "                type=\"messages\",\n",
    "                stop_btn=True, \n",
    "                submit_btn=True\n",
    "            )\n",
    "    \n",
    "    # Process file upload\n",
    "    file_input.change(\n",
    "        fn=process_file,\n",
    "        inputs=[file_input],\n",
    "        outputs=[status_output]\n",
    "    )\n",
    "    \n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53fc30e5-e780-4d14-8beb-37972aca2724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:283: UserWarning: Received additional kwargs {'handle_parsing_errors': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# give me a summary of the data provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4925d-332e-48f8-a0bb-9fb344f9c433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
